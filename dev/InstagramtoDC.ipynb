{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e3la/instagram2bepress/blob/main/InstagramtoDC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJp27grULlAO"
      },
      "source": [
        "# Welcome to this Instagram to DC tool!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHztwkUeLtzb"
      },
      "source": [
        "This project is was created using an avante guard technique of [vibecoding](https://en.wikipedia.org/wiki/Vibe_coding). I know enough python to be dangerous. If anything about this feels wrong, if the vibe is off, be like a tree and leaf. I try to share what the code is doing (as provided to me either by chatgpt, claude or gemini as I've been working on the project) and the code itself (likewise provided by ai). My end goal is batch upload an archive of instagram posts to digital commons.\n",
        "\n",
        "\"I\"? We? AI and I? wrote this in google colab, which is a instance of jupyter notebook. It's a tool for sharing and working with python and text to explain what is happening. There are textbooks and code boxes that are helping us on our journey. Buckle in! The first thing you'll need is a zip export from instagram. Whoever has the keys to the instagram account can visit https://www.instagram.com/download/request and get a zip. That's the file you'll need to start.\n",
        "\n",
        "This looks complicated, but take a deep breath, and know that the process is upload a zip and press 'play' multiple times until you can download a zip you can bring to digital commons for batch upload. If you need help with that bit ... get in touch with your support person there!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdSwTWpXgsK5"
      },
      "source": [
        "**What this code does:**\n",
        "\n",
        "The code block below handles uploading your Instagram archive `.zip` file into this Colab notebook environment.\n",
        "\n",
        "1.  `from google.colab import files`: Imports the necessary tools for file handling. - Okay, get ready, we're going to need the tools for moving files around!\n",
        "2.  `uploaded = files.upload()`: **Displays an \"Upload\" button** below this cell.\n",
        "    *   **==> Action Required <==**: Click the button and select your Instagram `.zip` file from your computer.\n",
        "3.  The rest of the code finds the name of the file you uploaded, stores it in the `zip_filename` variable, and prints the filename as confirmation.\n",
        "\n",
        "**Purpose:** To get your Instagram data file ready for the next steps in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "EWLymhShVca0",
        "outputId": "0825c879-615a-48d9-85f9-6392cb472f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68e41ad7-eb87-46c3-a7fd-681afcc9c348\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-68e41ad7-eb87-46c3-a7fd-681afcc9c348\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-998b86da85d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Upload the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get the uploaded file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the zip file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file name\n",
        "for filename in uploaded.keys():\n",
        "    zip_filename = filename\n",
        "    print(f\"Uploaded file: {zip_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwVFTHg9hvVz"
      },
      "source": [
        "**What the next code does:**\n",
        "\n",
        "It takes the `.zip` file you uploaded and **unzips** it, revealing all the files and folders inside your Instagram archive. It then **prints a list** of everything it found.\n",
        "\n",
        "1.  `extract_dir = 'extracted_instagram_data'`: Sets up a dedicated folder name where the unzipped files will be placed. This keeps things organized.\n",
        "2.  `with zipfile.ZipFile(...)`: Opens your uploaded `.zip` file.\n",
        "3.  `zip_ref.extractall(extract_dir)`: **Extracts all contents** from the zip file into the `extracted_instagram_data` folder.\n",
        "4.  `for root, dirs, files in os.walk(extract_dir)`: This is the part that explores the newly created folder and all its subfolders.\n",
        "5.  The `print()` statements states who many files were in the zip.\n",
        "\n",
        "**Purpose:** To unpack your Instagram archive and give you an overview of its structure and all the individual data files (like photos, messages, profile info, etc.) it contains.\n",
        "\n",
        "**Note:** Your Instagram archive might contain many files, so this list could be quite long! You can also visually explore the `extracted_instagram_data` folder using the file browser icon (looks like a folder 📁) on the left sidebar of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhHQYpcohsou",
        "outputId": "5f2c6c77-4779-4a1d-cc16-62fadd2edf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping 'instagram-umsllibraries-2025-03-07-Ardjbhx1.zip' into a folder named 'extracted_instagram_data'...\n",
            "Successfully unzipped the archive.\n",
            "\n",
            "-----------------------------------------\n",
            "Found 1445 files in total.\n",
            "Images: 1229\n",
            "MP4 videos: 103\n",
            "You can also browse these files using the 'Files' panel on the left sidebar.\n",
            "\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define a directory name to extract the contents into\n",
        "extract_dir = 'extracted_instagram_data'\n",
        "\n",
        "print(f\"Unzipping '{zip_filename}' into a folder named '{extract_dir}'...\")\n",
        "\n",
        "# Use a try-except block to handle potential errors during unzipping\n",
        "try:\n",
        "    # Open the zip file in read mode ('r')\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        # Extract all the contents into the specified directory\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Successfully unzipped the archive.\")\n",
        "\n",
        "    file_count = 0\n",
        "    image_count = 0\n",
        "    video_count = 0\n",
        "\n",
        "    # Walk through the directory tree (folders, subfolders, files)\n",
        "    for root, dirs, files in os.walk(extract_dir):\n",
        "        # Get the path relative to the extraction directory for cleaner display\n",
        "        #relative_path = os.path.relpath(root, extract_dir)\n",
        "        relative_path = root.replace(extract_dir + os.sep, '')\n",
        "\n",
        "        # Count all files within the current folder\n",
        "        for file in files:\n",
        "            file_count += 1\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp')):\n",
        "              image_count += 1\n",
        "            elif file.lower().endswith('.mp4'):\n",
        "              video_count += 1\n",
        "\n",
        "    print(\"\\n-----------------------------------------\")\n",
        "    print(f\"Found {file_count} files in total.\")\n",
        "    print(f\"Images: {image_count}\")\n",
        "    print(f\"MP4 videos: {video_count}\")\n",
        "    print(\"You can also browse these files using the 'Files' panel on the left sidebar.\")\n",
        "    print(\"\\n-----------------------------------------\")\n",
        "\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: The file '{zip_filename}' does not seem to be a valid zip archive. Please check the file and try uploading again.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Could not find the file '{zip_filename}'. Was the upload in the previous step successful?\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtP7mTRBhtIr"
      },
      "source": [
        "**What this next code block does:**\n",
        "\n",
        "This block focuses on **loading the data** from the three most relevant JSON files for understanding media content: `posts_1.json`, `reels.json`, and `stories.json`. These files contain metadata like captions, timestamps, and file paths for your posts, reels, and stories.\n",
        "\n",
        "1.  `import json`: Imports tools for reading JSON data.\n",
        "2.  **Find Activity Folder:** It first tries to automatically find the main folder within your unzipped archive (usually named after your username, like `syracuseuniversitylibraries_20231027`) by looking for a common file (`account_information.json`). If it can't find it, it defaults to `your_instagram_activity` (you might need to edit the code if this default is wrong for your archive).\n",
        "3.  **Define Paths:** It constructs the exact path to where these JSON files *should* be located (inside the `media` subfolder within the main activity folder).\n",
        "4.  **Load Files Loop:** It then attempts to:\n",
        "    *   **Check:** Verify if each file (`posts_1.json`, `reels.json`, `stories.json`) actually exists at the expected location.\n",
        "    *   **Open & Read:** If a file exists, it opens it using the correct `utf-8` encoding (important for special characters/emojis).\n",
        "    *   **Parse JSON:** It uses the `json.load()` function to convert the raw text from the file into a structured Python format (usually a list of dictionaries).\n",
        "    *   **Store Data:** The loaded data for each type (posts, reels, stories) is stored in a central dictionary called `instagram_media_data`. You can access the posts data later using `instagram_media_data['posts']`, reels using `instagram_media_data['reels']`, etc.\n",
        "5.  **Handle Missing Files/Errors:** If a file is missing (e.g., you have no Reels, so `reels.json` doesn't exist) or if there's an error reading a file (e.g., it's corrupted), it prints a message and stores `None` for that data type, preventing the script from crashing.\n",
        "6.  **Summary:** Finally, it prints a summary showing which files were successfully loaded and how many entries were found in each.\n",
        "\n",
        "**Purpose:** To extract the key metadata about posts, reels, and stories from their respective JSON files and load it into Python variables (`instagram_media_data['posts']`, `instagram_media_data['reels']`, `instagram_media_data['stories']`) so we can analyze or process it in later steps for potential repository migration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t0DwMgnjF-d",
        "outputId": "94fff164-e729-41a4-d6a2-f064e2e83620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using default: 'your_instagram_activity'.\n",
            "\n",
            "Looking for JSON files inside: 'extracted_instagram_data/your_instagram_activity/media'\n",
            "\n",
            "Attempting to load media:\n",
            " -> Posts: 'posts_1.json'\n",
            "    ✅ Loaded 646 entries.\n",
            " -> Reels: 'reels.json'\n",
            "    ✅ Loaded 25 flattened entries.\n",
            " -> Stories: 'stories.json'\n",
            "    ✅ Loaded 485 entries.\n",
            "\n",
            "--- Summary ---\n",
            "- Posts: ✅ 646 entries loaded\n",
            "- Reels: ✅ 25 entries loaded\n",
            "- Stories: ✅ 485 entries loaded\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# --- Configuration ---\n",
        "potential_base_dir = extract_dir  # Assumes this is defined earlier\n",
        "activity_folder_name = None\n",
        "\n",
        "# Detect main Instagram activity folder\n",
        "for item in os.listdir(potential_base_dir):\n",
        "    item_path = os.path.join(potential_base_dir, item)\n",
        "    if os.path.isdir(item_path) and 'account_information.json' in os.listdir(item_path):\n",
        "        activity_folder_name = item\n",
        "        print(f\"Automatically detected activity folder: '{activity_folder_name}'\")\n",
        "        break\n",
        "\n",
        "# Fallback default\n",
        "if not activity_folder_name:\n",
        "    activity_folder_name = 'your_instagram_activity'\n",
        "    print(f\"Using default: '{activity_folder_name}'.\")\n",
        "\n",
        "# Path to media folder\n",
        "media_path = os.path.join(potential_base_dir, activity_folder_name, 'media')\n",
        "print(f\"\\nLooking for JSON files inside: '{media_path}'\")\n",
        "\n",
        "# Files we want to parse\n",
        "files_to_load = {\n",
        "    \"posts\": os.path.join(media_path, 'posts_1.json'),\n",
        "    \"reels\": os.path.join(media_path, 'reels.json'),\n",
        "    \"stories\": os.path.join(media_path, 'stories.json')\n",
        "}\n",
        "\n",
        "instagram_media_data = {}\n",
        "\n",
        "# --- Load and normalize JSON ---\n",
        "print(\"\\nAttempting to load media:\")\n",
        "\n",
        "for media_type, file_path in files_to_load.items():\n",
        "    print(f\" -> {media_type.title()}: '{os.path.basename(file_path)}'\")\n",
        "\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"    ⚠️ File not found. Skipping.\")\n",
        "            instagram_media_data[media_type] = None\n",
        "            continue\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if isinstance(data, list):  # For posts_1.json\n",
        "            instagram_media_data[media_type] = data\n",
        "            print(f\"    ✅ Loaded {len(data)} entries.\")\n",
        "\n",
        "        elif isinstance(data, dict):\n",
        "            # Handle known top-level keys\n",
        "            top_level_key = {\n",
        "                \"reels\": \"ig_reels_media\",\n",
        "                \"stories\": \"ig_stories\"\n",
        "            }.get(media_type)\n",
        "\n",
        "            if top_level_key in data:\n",
        "                # Check if it's a flat list or list of groups\n",
        "                first_entry = data[top_level_key][0] if data[top_level_key] else {}\n",
        "\n",
        "                if isinstance(first_entry, dict) and 'media' in first_entry:\n",
        "                    # Flatten nested media lists\n",
        "                    flat_media = []\n",
        "                    for group in data[top_level_key]:\n",
        "                        if isinstance(group, dict) and 'media' in group:\n",
        "                            flat_media.extend(group['media'])\n",
        "                    instagram_media_data[media_type] = flat_media\n",
        "                    print(f\"    ✅ Loaded {len(flat_media)} flattened entries.\")\n",
        "                elif isinstance(data[top_level_key], list):\n",
        "                    # Already flat list\n",
        "                    instagram_media_data[media_type] = data[top_level_key]\n",
        "                    print(f\"    ✅ Loaded {len(data[top_level_key])} entries.\")\n",
        "                else:\n",
        "                    print(f\"    ⚠️ Unsupported structure for {media_type}.\")\n",
        "                    instagram_media_data[media_type] = None\n",
        "            else:\n",
        "                print(f\"    ⚠️ Expected key '{top_level_key}' not found.\")\n",
        "                instagram_media_data[media_type] = None\n",
        "\n",
        "        else:\n",
        "            print(f\"    ❌ Unsupported JSON structure in {media_type}.\")\n",
        "            instagram_media_data[media_type] = None\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"    ❌ Could not parse JSON (corrupt?).\")\n",
        "        instagram_media_data[media_type] = None\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Error: {e}\")\n",
        "        instagram_media_data[media_type] = None\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"\\n--- Summary ---\")\n",
        "for media_type, data in instagram_media_data.items():\n",
        "    if isinstance(data, list):\n",
        "        print(f\"- {media_type.capitalize()}: ✅ {len(data)} entries loaded\")\n",
        "    else:\n",
        "        print(f\"- {media_type.capitalize()}: ❌ Not loaded or no valid entries\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyqFyi80U8fH"
      },
      "source": [
        "This section is grabbing your instagram handle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5n7_AZxxdAv",
        "outputId": "a8de2aed-f7f3-4ec1-d502-651655fd4989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Username: umsllibraries\n"
          ]
        }
      ],
      "source": [
        "# Example filename string (replace with your actual variable if needed)\n",
        "# zip_filename = \"...\" # Assuming this variable holds the filename\n",
        "#zip_filename = \"instagram-umsllibraries-2025-03-07-Ardjbhx1.zip\"\n",
        "\n",
        "# Remove the 'instagram-' prefix if it exists\n",
        "if zip_filename.startswith(\"instagram-\"):\n",
        "    temp_name = zip_filename[len(\"instagram-\"):] # Get everything after 'instagram-'\n",
        "else:\n",
        "    temp_name = zip_filename # Handle cases where it might not start with 'instagram-'\n",
        "\n",
        "# Split the remaining string by the hyphen '-'\n",
        "parts = temp_name.split('-', 1) # Split only on the *first* hyphen found\n",
        "\n",
        "# The desired part is the first element after the split\n",
        "if len(parts) > 0:\n",
        "    instausername = parts[0]\n",
        "    print(f\"Username: {instausername}\")\n",
        "else:\n",
        "    print(\"Could not extract using split method (unexpected format).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "YDxGT_JlEp_-",
        "outputId": "21eacb5e-c719-4942-eba6-0eb7476c9f67"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'download'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-87c7174aba20>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# --- Download the zip archive ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'download'"
          ]
        }
      ],
      "source": [
        "# prompt: I want to export a zip of all the reels, posts and stories with a csv metadata file and readme\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# --- Create README ---\n",
        "readme_content = \"\"\"\n",
        "This archive contains Instagram data exported from the Instagram app.\n",
        "The archive includes:\n",
        "\n",
        "- **Reels:** Video posts.\n",
        "- **Posts:** Photos and videos.\n",
        "- **Stories:** Photo and video stories.\n",
        "- **metadata.csv:** A CSV file containing metadata for the exported media.\n",
        "\"\"\"\n",
        "\n",
        "# --- Create metadata.csv ---\n",
        "metadata_file = \"metadata.csv\"\n",
        "with open(metadata_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"media_type\", \"filename\", \"timestamp\", \"caption\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for media_type, data in instagram_media_data.items():\n",
        "        if data:\n",
        "          for item in data:\n",
        "              try:\n",
        "                if media_type == \"posts\":\n",
        "                    filename = item.get(\"image_versions2\", {}).get(\"candidates\", [{}])[0].get(\"url\")\n",
        "                    timestamp = item.get(\"taken_at\")\n",
        "                    caption = item.get(\"caption\", {}).get(\"text\")\n",
        "                elif media_type == \"reels\":\n",
        "                    filename = item.get(\"video_versions\", [{}])[0].get(\"url\")\n",
        "                    timestamp = item.get(\"taken_at\")\n",
        "                    caption = item.get(\"caption\", {}).get(\"text\")\n",
        "                elif media_type == \"stories\":\n",
        "                    filename = item.get(\"image_versions2\", {}).get(\"candidates\", [{}])[0].get(\"url\")\n",
        "                    timestamp = item.get(\"taken_at\")\n",
        "                    caption = item.get(\"caption\", {}).get(\"text\")\n",
        "\n",
        "                writer.writerow({\n",
        "                    \"media_type\": media_type,\n",
        "                    \"filename\": filename,\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"caption\": caption,\n",
        "                })\n",
        "              except Exception as e:\n",
        "                print(f\"Error processing {media_type} item: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Create and populate the zip archive ---\n",
        "zip_filename = f\"{instausername}_instagram_archive.zip\"\n",
        "with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "\n",
        "    # Add README\n",
        "    zipf.writestr(\"README.txt\", readme_content)\n",
        "\n",
        "    # Add metadata\n",
        "    zipf.write(metadata_file)\n",
        "\n",
        "\n",
        "    # Add media files (reels, posts, stories)\n",
        "    for media_type, data in instagram_media_data.items():\n",
        "      if data:\n",
        "        for item in data:\n",
        "          try:\n",
        "            if media_type == \"posts\":\n",
        "              filename = item.get(\"image_versions2\", {}).get(\"candidates\", [{}])[0].get(\"url\")\n",
        "            elif media_type == \"reels\":\n",
        "              filename = item.get(\"video_versions\", [{}])[0].get(\"url\")\n",
        "            elif media_type == \"stories\":\n",
        "              filename = item.get(\"image_versions2\", {}).get(\"candidates\", [{}])[0].get(\"url\")\n",
        "            # Assuming 'filename' is a direct path or URL, adjust as needed for your file structure\n",
        "            if filename and os.path.exists(filename):\n",
        "              zipf.write(filename, arcname=os.path.basename(filename)) # Add to zip preserving filename\n",
        "          except Exception as e:\n",
        "              print(f\"Error adding file to zip: {e}\")\n",
        "\n",
        "# --- Download the zip archive ---\n",
        "files.download(zip_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZBTEXNewQb9",
        "outputId": "18a21098-e141-4b34-ab1c-5438628f1645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing to export 25 Reels...\n",
            "Metadata written to CSV: extracted_instagram_data/reels_export/reels_metadata.csv\n",
            "ZIP archive created: extracted_instagram_data/reels_export/reels_package.zip\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from shutil import copy2\n",
        "\n",
        "# --- Prompt for Instagram handle ---\n",
        "instagram_handle = instausername;\n",
        "\n",
        "# --- Configuration ---\n",
        "media_type = 'reels'\n",
        "output_dir = os.path.join(extract_dir, f'{media_type}_export')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# CSV and ZIP file paths\n",
        "csv_path = os.path.join(output_dir, f'{media_type}_metadata.csv')\n",
        "readme_path = os.path.join(output_dir, 'README.txt')\n",
        "zip_path = os.path.join(output_dir, f'{media_type}_package.zip')\n",
        "\n",
        "# Get loaded Reels data\n",
        "reels_data = instagram_media_data.get(media_type)\n",
        "if not reels_data:\n",
        "    print(\"No Reels data loaded.\")\n",
        "else:\n",
        "    print(f\"Preparing to export {len(reels_data)} Reels...\")\n",
        "\n",
        "    # 1. Write CSV\n",
        "    with open(csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['filename', 'creation_date', 'original_uri', 'subtitles_uri']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Keep track of copied files for ZIP\n",
        "        copied_files = []\n",
        "\n",
        "        for i, item in enumerate(reels_data):\n",
        "            uri = item.get('uri')\n",
        "            if not uri:\n",
        "                continue\n",
        "\n",
        "            media_path = os.path.join(extract_dir, uri)\n",
        "            if not os.path.exists(media_path):\n",
        "                print(f\"Warning: File not found - {media_path}\")\n",
        "                continue\n",
        "\n",
        "            # Get timestamp\n",
        "            timestamp = item.get('creation_timestamp')\n",
        "            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d') if timestamp else 'unknown-date'\n",
        "\n",
        "            # Prepare export filename using handle and date\n",
        "            ext = os.path.splitext(uri)[-1]\n",
        "            export_filename = f\"instagram_{instagram_handle}_reel_{date_str}_{i+1}_{os.path.splitext(os.path.basename(uri))[0]}{ext}\"\n",
        "            export_path = os.path.join(output_dir, export_filename)\n",
        "            copy2(media_path, export_path)\n",
        "            copied_files.append(export_path)\n",
        "\n",
        "            # Subtitles (if any)\n",
        "            subtitles_uri = ''\n",
        "            try:\n",
        "                subtitles_uri = item['media_metadata']['video_metadata']['subtitles']['uri']\n",
        "            except KeyError:\n",
        "                pass\n",
        "\n",
        "            writer.writerow({\n",
        "                'filename': export_filename,\n",
        "                'creation_date': date_str,\n",
        "                'original_uri': uri,\n",
        "                'subtitles_uri': subtitles_uri\n",
        "            })\n",
        "\n",
        "    print(f\"Metadata written to CSV: {csv_path}\")\n",
        "\n",
        "    # 2. Write README file\n",
        "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"\"\"Instagram Reels Export Package\n",
        "===============================\n",
        "\n",
        "Handle: @{instagram_handle}\n",
        "Exported: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "This package contains:\n",
        "- All exported Reels in video format.\n",
        "- A CSV file (reels_metadata.csv) with metadata for each reel.\n",
        "- This README.txt file for context.\n",
        "\n",
        "Fields in the CSV:\n",
        "- filename: The name of the exported video file.\n",
        "- creation_date: ISO-formatted creation date of the reel.\n",
        "- original_uri: The original relative URI from the Instagram archive.\n",
        "- subtitles_uri: If available, the URI of associated subtitles.\n",
        "\n",
        "Generated by your local Instagram archive helper script.\n",
        "\"\"\")\n",
        "\n",
        "    # 3. Zip everything up\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        zipf.write(csv_path, arcname=os.path.basename(csv_path))\n",
        "        zipf.write(readme_path, arcname='README.txt')\n",
        "        for file_path in copied_files:\n",
        "            zipf.write(file_path, arcname=os.path.basename(file_path))\n",
        "\n",
        "    print(f\"ZIP archive created: {zip_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA8SBuUsy8ro",
        "outputId": "608d50b0-d0fe-4364-de5a-50c432545acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing to export 25 Reels...\n",
            "Metadata written to CSV: extracted_instagram_data/reels_export/reels_metadata.csv\n",
            "\n",
            "✅ ZIP archive created: extracted_instagram_data/reels_export/reels_package.zip\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from shutil import copy2\n",
        "\n",
        "# --- Prompt for Instagram handle ---\n",
        "instagram_handle = instausername;\n",
        "if not instagram_handle:\n",
        "    raise ValueError(\"Instagram handle cannot be empty.\")\n",
        "\n",
        "# --- Configuration ---\n",
        "media_type = 'reels'\n",
        "output_dir = os.path.join(extract_dir, f'{media_type}_export')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# File paths\n",
        "csv_path = os.path.join(output_dir, f'{media_type}_metadata.csv')\n",
        "readme_path = os.path.join(output_dir, 'README.txt')\n",
        "zip_path = os.path.join(output_dir, f'{media_type}_package.zip')\n",
        "\n",
        "# Get loaded Reels data\n",
        "reels_data = instagram_media_data.get(media_type)\n",
        "if not reels_data:\n",
        "    print(\"No Reels data loaded.\")\n",
        "else:\n",
        "    print(f\"Preparing to export {len(reels_data)} Reels...\")\n",
        "\n",
        "    copied_files = []\n",
        "\n",
        "    # 1. Write metadata CSV\n",
        "    with open(csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['filename', 'creation_date', 'original_uri', 'subtitles_uri', 'subtitles_file']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for i, item in enumerate(reels_data):\n",
        "            uri = item.get('uri')\n",
        "            if not uri:\n",
        "                continue\n",
        "\n",
        "            media_path = os.path.join(extract_dir, uri)\n",
        "            if not os.path.exists(media_path):\n",
        "                print(f\"Warning: File not found - {media_path}\")\n",
        "                continue\n",
        "\n",
        "            # Format creation date\n",
        "            timestamp = item.get('creation_timestamp')\n",
        "            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d') if timestamp else 'unknown-date'\n",
        "\n",
        "            # Prepare export filenames\n",
        "            ext = os.path.splitext(uri)[-1]\n",
        "            base_filename = f\"instagram_{instagram_handle}_reel_{date_str}_{i+1}\"\n",
        "            video_filename = base_filename + ext\n",
        "            video_path = os.path.join(output_dir, video_filename)\n",
        "            copy2(media_path, video_path)\n",
        "            copied_files.append(video_path)\n",
        "\n",
        "            # Handle subtitles\n",
        "            subtitles_uri = ''\n",
        "            subtitles_path = ''\n",
        "            try:\n",
        "                subtitles_uri = item['media_metadata']['video_metadata']['subtitles']['uri']\n",
        "                original_subs_path = os.path.join(extract_dir, subtitles_uri)\n",
        "                if os.path.exists(original_subs_path):\n",
        "                    subtitles_path = os.path.join(output_dir, base_filename + '.srt')\n",
        "                    copy2(original_subs_path, subtitles_path)\n",
        "                    copied_files.append(subtitles_path)\n",
        "                else:\n",
        "                    print(f\"Subtitles URI exists but file not found: {original_subs_path}\")\n",
        "            except KeyError:\n",
        "                pass\n",
        "\n",
        "            writer.writerow({\n",
        "                'filename': video_filename,\n",
        "                'creation_date': date_str,\n",
        "                'original_uri': uri,\n",
        "                'subtitles_uri': subtitles_uri,\n",
        "                'subtitles_file': os.path.basename(subtitles_path) if subtitles_path else ''\n",
        "            })\n",
        "\n",
        "    print(f\"Metadata written to CSV: {csv_path}\")\n",
        "\n",
        "    # 2. Write README file\n",
        "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(f\"\"\"Instagram Reels Export Package\n",
        "===============================\n",
        "\n",
        "Handle: @{instagram_handle}\n",
        "Exported: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "This package contains:\n",
        "- Exported Reels in video format.\n",
        "- Subtitles (SRT files) if available.\n",
        "- A CSV file (reels_metadata.csv) with metadata.\n",
        "- This README.txt file.\n",
        "\n",
        "CSV Fields:\n",
        "- filename: Exported video filename\n",
        "- creation_date: Date the reel was created\n",
        "- original_uri: Path in original archive\n",
        "- subtitles_uri: Path to subtitle in original archive\n",
        "- subtitles_file: Renamed .srt subtitle file (if present)\n",
        "\n",
        "Generated by your custom Instagram archive export tool.\n",
        "\"\"\")\n",
        "\n",
        "    # 3. Zip it all up\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        zipf.write(csv_path, arcname=os.path.basename(csv_path))\n",
        "        zipf.write(readme_path, arcname='README.txt')\n",
        "        for file_path in copied_files:\n",
        "            zipf.write(file_path, arcname=os.path.basename(file_path))\n",
        "\n",
        "    print(f\"\\n✅ ZIP archive created: {zip_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w-nyI2mNzggg",
        "outputId": "2f8f0045-3060-4227-d7ae-f7d8def91dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ZIP archive created: /content/reels_package.zip\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href=\"/content/reels_package.zip\" download>📦 Click here to download your Reels ZIP package</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2. Zip everything up\n",
        "zip_path = '/content/reels_package.zip'\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    zipf.write(csv_path, arcname='reels_metadata.csv')\n",
        "    for file_path in copied_files:\n",
        "        zipf.write(file_path, arcname=os.path.basename(file_path))\n",
        "    # Optional: include SRT files if you downloaded any\n",
        "\n",
        "print(f\"ZIP archive created: {zip_path}\")\n",
        "\n",
        "# Display download link\n",
        "if os.path.exists(output_path):\n",
        "  # 5. Trigger the download in your browser\n",
        "  print(f\"\\nAttempting to download '{output_filename}'...\")\n",
        "  print(\"Check your browser's downloads!\")\n",
        "  files.download(output_path) # Use the full path or just the filename if in /content/\n",
        "else:\n",
        "  print(f\"\\nError: File '{output_path}' was not found. Cannot download.\")\n",
        "\n",
        "display(HTML(f'<a href=\"{output_path}\" download>📦 Click here to download your Reels ZIP package</a>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh0KD7QXGChR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
